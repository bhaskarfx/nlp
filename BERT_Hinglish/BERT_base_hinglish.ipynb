{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9c65dc24-47dd-4288-8c42-3512a3a78d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "import itertools\n",
    "import random\n",
    "from typing import List\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch,csv\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "798fc690-7bdf-4669-a0d7-bfee4fcf083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select device GPU, CPU or any other\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f6e2dfc9-56d4-40cb-9fb5-2e7685acf10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'tweet', 'label'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     1266\n",
       "positive     853\n",
       "negative     363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Statistics\n",
    "d=pd.read_csv(\"data/train.csv\")\n",
    "d[\"label\"] = d[\"label\"].replace(\"posiitve\", \"positive\")\n",
    "print(d.columns)\n",
    "d[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2419ce3f-9a9a-4298-aef4-0e89d6c08b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     305\n",
       "positive    219\n",
       "negative     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Statistics\n",
    "d=pd.read_csv(\"data/dev.csv\")\n",
    "d[\"label\"] = d[\"label\"].replace(\"posiitve\", \"positive\")\n",
    "d[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72811ed8-6331-4fc4-a85f-14eccc40ff1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     386\n",
       "positive    280\n",
       "negative    110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Statistics\n",
    "d=pd.read_csv(\"data/test.csv\")\n",
    "d[\"label\"] = d[\"label\"].replace(\"posiitve\", \"positive\")\n",
    "d[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "66b4b21f-1acd-48ad-a58b-77c17a5d649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv and return list of instances\n",
    "\n",
    "def read_data(path, to_dataset=True):\n",
    "    '''\n",
    "    read csv and return list of instances\n",
    "    '''\n",
    "    rows = []; label_dict = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "    \n",
    "    # read data\n",
    "    df=pd.read_csv(path)\n",
    "    for i in range(len(df)):\n",
    "        text = df['tweet'].loc[i]\n",
    "        \n",
    "        #remove extra space\n",
    "        wrds = text.split(\" \")\n",
    "        new_wrds = [wrd.strip() for wrd in wrds]\n",
    "        text = \" \".join(new_wrds)\n",
    "        \n",
    "        label = df['label'].loc[i]\n",
    "        if(label in [\"posiitve\"]):\n",
    "            label=\"positive\"\n",
    "            \n",
    "        label = label_dict[label]\n",
    "        \n",
    "        \n",
    "        rows.append({\n",
    "            'id': i,\n",
    "            'text': text,\n",
    "            'label': label,\n",
    "        })\n",
    "        \n",
    "    # Convert to Hugging Face Dataset\n",
    "    if to_dataset:\n",
    "        # to object\n",
    "        rows = datasets.Dataset.from_list(rows)\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "99c39209-f9db-4d1d-b7fa-ec1970112f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    '''\n",
    "    calculate accuracy\n",
    "    '''\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "26252e2e-cf3b-4b9e-b438-c020298cdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT:\n",
    "    '''\n",
    "    with tokenizer and auto model\n",
    "    '''\n",
    "    def __init__(self, MODEL, num_labels):\n",
    "        '''\n",
    "        basic\n",
    "        '''\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=num_labels)\n",
    "    \n",
    "    def tokenize(self, samples):\n",
    "        '''\n",
    "        run tokenization\n",
    "        '''\n",
    "        return self.tokenizer(samples[\"text\"], padding=\"max_length\", max_length=80, truncation=True)\n",
    "    \n",
    "    def run(self, sample):\n",
    "        '''\n",
    "        run for a single instance\n",
    "        '''\n",
    "        # print(\"sample\",sample)\n",
    "        encoded_input = self.tokenizer(sample, return_tensors='pt')\n",
    "        # print(\"encoded\")\n",
    "        output = self.model(**encoded_input)['logits'][0].detach().numpy()\n",
    "\n",
    "        return np.argmax(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fdea01ca-19ed-420e-a9c3-8a0902d127ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/robust/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "# init model\n",
    "model_module = BERT(MODEL, num_labels=3)\n",
    "\n",
    "# read dataset\n",
    "train_dataset = read_data('data/train.csv')\n",
    "dev_dataset = read_data('data/dev.csv')\n",
    "\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        'train': train_dataset, \n",
    "        'dev': dev_dataset, \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a360d3d-c910-4533-a3ae-7d75b9926940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label'],\n",
       "        num_rows: 2482\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'text', 'label'],\n",
       "        num_rows: 621\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c75bc46d-3b24-4662-82ef-de5dce363f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e839549a874f6a98893621ab709832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2482 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b1d8d233c54ea3bd6a5d95a6237adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/621 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize dataset (multiple examples at same time)\n",
    "tok_dataset = dataset.map(model_module.tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fcf9c1fe-f4a0-43a1-b75c-f0c9b614ed45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2482\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 621\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "input_ids\n",
    "These are the numerical representations of tokens from the modelâ€™s vocabulary.\n",
    "Each token is mapped to a unique ID.\n",
    "101 â†’ [CLS] (Start of sentence)\n",
    "102 â†’ [SEP] (End of sentence)\n",
    "[Input 1 [SEP] Input 2]\n",
    "\n",
    "attention_mask\n",
    "Specifies which tokens should be attended to and which should be ignored (useful for padding).\n",
    "1 means the token is real, 0 means it's padding.\n",
    "\n",
    "token_type_ids (Segment IDs)\n",
    "Helps differentiate between two sequences in a single input.\n",
    "'''\n",
    "tok_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "59430957-946a-40a3-8ef2-da35485bfcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0mment scroll kar kar ke hairan hogaye hum\n",
      "['[CLS]', 'c', '##0', '##mme', '##nt', 'scroll', 'ka', '##r', 'ka', '##r', 'ke', 'hair', '##an', 'hog', '##ay', '##e', 'hum', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[101, 1039, 2692, 20058, 3372, 17186, 10556, 2099, 10556, 2099, 17710, 2606, 2319, 27589, 4710, 2063, 14910, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tok_dataset[\"train\"][1][\"text\"])\n",
    "print(model_module.tokenizer.convert_ids_to_tokens(tok_dataset[\"train\"][1][\"input_ids\"]))\n",
    "print(tok_dataset[\"train\"][1][\"input_ids\"])\n",
    "print(tok_dataset[\"train\"][1][\"token_type_ids\"])\n",
    "print(tok_dataset[\"train\"][1][\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c809ae13-e215-458b-b73b-2790978cfa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/robust/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./logs_bertbase\",           # Where model checkpoints/logs will be saved\n",
    "    num_train_epochs=1,            # Number of training epochs\n",
    "    learning_rate=3e-05,           # Learning rate (3e-5 = 0.00003)\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",    # Evaluate the model at the end of each epoch\n",
    "    per_device_train_batch_size=8,  # Training batch size\n",
    "    per_device_eval_batch_size=8, # Eval batch size\n",
    "    load_best_model_at_end=True, # Load best model when training ends\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3831147e-f92f-464c-9324-04b3b3745310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='311' max='311' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [311/311 00:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.834531</td>\n",
       "      <td>0.631240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=311, training_loss=0.9186015727052351, metrics={'train_runtime': 39.273, 'train_samples_per_second': 63.199, 'train_steps_per_second': 7.919, 'total_flos': 102038672312640.0, 'train_loss': 0.9186015727052351, 'epoch': 1.0})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_module.model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_dataset[\"train\"],\n",
    "    eval_dataset=tok_dataset[\"dev\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa72fdf3-c0a5-4eeb-b6e7-2c19914714f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/robust/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Inferencing\n",
    "\n",
    "# dataset\n",
    "rows = read_data(\"data/test.csv\", to_dataset=False)\n",
    "\n",
    "#Load model \n",
    "MODEL = \"logs_bertbase/\"\n",
    "\n",
    "model_module = BERT(MODEL, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f5213351-5d58-42e3-869a-e3c0d0ee7f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:30<00:00, 25.24it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = []; gold = []\n",
    "for row in tqdm(rows, total=len(rows)):\n",
    "    pred.append(model_module.run(row['text'])); gold.append(row['label'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e06dcf9-c59e-41ee-a53d-949629ec2669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.6842783505154639\n",
      "F1: 0.650528674335281\n",
      "-------------------------\n",
      "[[ 53  36  21]\n",
      " [ 18 288  80]\n",
      " [  9  81 190]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(np.array(pred) == np.array(gold)) / len(gold)\n",
    "print(\"ACCURACY:\", accuracy)\n",
    "\n",
    "# f1 score\n",
    "for mode in ['macro']:\n",
    "    f1 = f1_score(gold, pred, average=mode)\n",
    "    print(f\"F1: {f1}\")\n",
    "print('-------------------------')\n",
    "\n",
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(gold, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524f372-5e4b-4bec-a9a0-32fad61e4287",
   "metadata": {},
   "source": [
    "Evaluating Robustness of Sentiment Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3cec3450-0c76-4342-b64b-265a61348f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate phonetic perturbations\n",
    "class PhoneticPerturbations():\n",
    "    \n",
    "    def __init__(\n",
    "        self, seed: int = 0):\n",
    "        \n",
    "        self.seed=seed\n",
    "        \n",
    "    \n",
    "    def pho_50(self, sentence: str):\n",
    "        random.seed(self.seed)\n",
    "        sentence_list = sentence.split()\n",
    "        l=len(sentence_list)\n",
    "        k_fifty=int(l/2)\n",
    "       \n",
    "        \n",
    "        if(k_fifty==0):\n",
    "            k_fifty=1\n",
    "       \n",
    "        perturbed_texts = []\n",
    "        subwrd_dict={\"aa\": \"a\", \"i\": \"ee\", \"r\": \"ri\", \"o\": \"oo\", \"au\": \"ou\", \"ka\": \"k\", \"kha\": \"kh\", \"ga\": \"g\", \n",
    "\t\t\t\t\"gha\": \"gh\", \"ca\": \"c\",\"cha\": \"ch\", \"sa\":\"sh\", \"jha\": \"jh\", \"bha\":\"v\", \"ta\": \"t\", \"tha\": \"th\", \"da\": \"d\", \"dha\": \"dh\", \"na\":\"n\", \n",
    "\t\t\t\t\"pa\": \"p\", \"pha\":\"f\", \"ba\": \"b\", \"ma\": \"m\", \"ya\":\"y\", \"ra\": \"rh\", \"la\": \"l\", \"ja\": \"z\", \"ha\": \"h\"}\n",
    "        sub_keys=subwrd_dict.keys();sub_wrds=subwrd_dict.values()\n",
    "        all_roots=list(subwrd_dict.keys())\n",
    "               \n",
    "        # Perturb the input sentence \n",
    "        cnt=1\n",
    "        for idx, word in enumerate(sentence_list):\n",
    "            \n",
    "            if(cnt>k_fifty):\n",
    "                break\n",
    "               \n",
    "            else:\n",
    "                for j in range(len(all_roots)):\n",
    "                    # print(all_roots[j])\n",
    "                    if(all_roots[j] in word):\n",
    "                        word=word.replace(all_roots[j], subwrd_dict[all_roots[j]])\n",
    "                    \n",
    "                sentence_list[idx]=word\n",
    "                cnt=cnt+1\n",
    "                \n",
    "\n",
    "        perturbed_texts=\" \".join(sentence_list)\n",
    "\n",
    "        return perturbed_texts\n",
    "\n",
    "    def pho_25(self, sentence: str):\n",
    "        random.seed(self.seed)\n",
    "        sentence_list = sentence.split()\n",
    "        l=len(sentence_list)\n",
    "        k_twentyfive=int(l/4)\n",
    "       \n",
    "        \n",
    "        if(k_twentyfive==0):\n",
    "            k_twentyfive=1\n",
    "       \n",
    "        perturbed_texts = []\n",
    "        subwrd_dict={\"aa\": \"a\", \"i\": \"ee\", \"r\": \"ri\", \"o\": \"oo\", \"au\": \"ou\", \"ka\": \"k\", \"kha\": \"kh\", \"ga\": \"g\", \n",
    "\t\t\t\t\"gha\": \"gh\", \"ca\": \"c\",\"cha\": \"ch\", \"sa\":\"sh\", \"jha\": \"jh\", \"bha\":\"v\", \"ta\": \"t\", \"tha\": \"th\", \"da\": \"d\", \"dha\": \"dh\", \"na\":\"n\", \n",
    "\t\t\t\t\"pa\": \"p\", \"pha\":\"f\", \"ba\": \"b\", \"ma\": \"m\", \"ya\":\"y\", \"ra\": \"rh\", \"la\": \"l\", \"ja\": \"z\", \"ha\": \"h\"}\n",
    "        \n",
    "        sub_keys=subwrd_dict.keys();sub_wrds=subwrd_dict.values()\n",
    "        all_roots=list(subwrd_dict.keys())\n",
    "               \n",
    "        # Perturb the input sentence \n",
    "        cnt=1\n",
    "        for idx, word in enumerate(sentence_list):\n",
    "            \n",
    "            if(cnt>k_twentyfive):\n",
    "                break\n",
    "               \n",
    "            else:\n",
    "                for j in range(len(all_roots)):\n",
    "                    # print(all_roots[j])\n",
    "                    if(all_roots[j] in word):\n",
    "                        word=word.replace(all_roots[j], subwrd_dict[all_roots[j]])\n",
    "                    \n",
    "                sentence_list[idx]=word\n",
    "                cnt=cnt+1\n",
    "                \n",
    "\n",
    "        perturbed_texts=\" \".join(sentence_list)\n",
    "\n",
    "        return perturbed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d80c7033-05e1-4061-a3c6-6cfd095017d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=PhoneticPerturbations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f78f2073-f2c6-4d1a-ae6f-f9fbaf9aac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776 Index(['Unnamed: 0', 'tweet', 'label'], dtype='object')\n",
      "Index(['Unnamed: 0', 'tweet', 'label', 'adv_text_50', 'adv_text_25'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Read test file and apply perturbations\n",
    "\n",
    "df=pd.read_csv(\"data/test.csv\")\n",
    "print(len(df), df.columns)\n",
    "\n",
    "adv_text_50=[];adv_text_25=[]\n",
    "for i in range(len(df)):\n",
    "    t=pp.pho_50(df.tweet.loc[i])\n",
    "    t1=pp.pho_25(df.tweet.loc[i])\n",
    "    \n",
    "    adv_text_50.append(t)\n",
    "    adv_text_25.append(t1)\n",
    "    \n",
    "df[\"adv_text_50\"] = adv_text_50\n",
    "df[\"adv_text_25\"] = adv_text_25\n",
    "\n",
    "print(df.columns)\n",
    "df.to_csv(\"data/adv_test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe98cbba-fe31-46fb-80ad-4d2f9c23be05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kon kareaga rea terea sath bt tujhsea acha dog sea bt kr lu\n",
      "Koon krieag riea terea sath bt tujhsea acha dog sea bt kr lu\n",
      "Koon krieag riea teriea shth bt tujhsea acha dog sea bt kr lu\n"
     ]
    }
   ],
   "source": [
    "print(df[\"tweet\"][0])\n",
    "print(df[\"adv_text_25\"][0])\n",
    "print(df[\"adv_text_50\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c7b0365-f831-44d5-8f60-4752570a4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model on perturbed dataset#\n",
    "label_dict1 = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "def read_adv_data(path):\n",
    "    '''\n",
    "    read adv csv\n",
    "    '''\n",
    "    dataset = {}\n",
    "    cnt=0\n",
    "    with open(path, mode ='r') as f:\n",
    "        data_f = csv.reader(f)\n",
    "        # skip header\n",
    "        next(data_f)\n",
    "\n",
    "        for line in data_f:\n",
    "            cnt=cnt+1\n",
    "            # print(\"hiiiiiii\",cnt,line)\n",
    "            # label = label_dict1[line[-1]]\n",
    "            label = line[3]\n",
    "\n",
    "            dataset[str(line[0])] = {\n",
    "                'adv_text_25': line[4].strip(),\n",
    "                'adv_text_50': line[3].strip(),\n",
    "                'label': label\n",
    "            }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "801c102b-23ec-4559-af56-972839b5b11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/robust/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 776 776\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "rows = read_data(\"data/test.csv\", to_dataset=False)\n",
    "\n",
    "# load adv dataset\n",
    "adv_rows = read_adv_data(\"data/adv_test_set.csv\")\n",
    "\n",
    "print(\"len\", len(rows), len(adv_rows))\n",
    "\n",
    "MODEL = \"./logs_bertbase\"\n",
    "# init model\n",
    "model_module = BERT(MODEL, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "30d84e9d-5e17-46a2-bd56-5108bb953b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:48<00:00, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.6842783505154639\n",
      "F1: 0.650528674335281\n",
      "-------------------------\n",
      "\n",
      "[[ 53  36  21]\n",
      " [ 18 288  80]\n",
      " [  9  81 190]] \n",
      "\n",
      "ACCURACY: 0.5502577319587629\n",
      "F1: 0.4907676335919105\n",
      "-------------------------\n",
      "\n",
      "[[ 33  51  26]\n",
      " [ 26 267  93]\n",
      " [ 18 135 127]] \n",
      "\n",
      "adv check: 531, adv success: 104\n",
      "adv success rate: 19.58568738229755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 0.25 perturbations\n",
    "\n",
    "adv_check = 0; adv_success = 0\n",
    "\n",
    "pred = []; adv_pred = []; gold = []; cnt = 0\n",
    "for row in tqdm(rows, total=len(rows)):\n",
    "    cnt = cnt+1\n",
    "\n",
    "    predicted = model_module.run(row['text']) \n",
    "    label = row['label']\n",
    "    # print(predicted,label)\n",
    "    \n",
    "    if predicted == label:\n",
    "        adv_check += 1\n",
    "        # rerun with adv claim\n",
    "        # print(adv_rows[str(row['id'])]['adv_text'])\n",
    "        adv_predicted = model_module.run(adv_rows[str(row['id'])]['adv_text_25'])\n",
    "        # print(\"adv_predicted\", adv_predicted, predicted)\n",
    "        if adv_predicted != predicted:\n",
    "            # on success\n",
    "            adv_success += 1\n",
    "    else:\n",
    "        adv_predicted = predicted\n",
    "    \n",
    "\n",
    "    pred.append(predicted); adv_pred.append(adv_predicted); gold.append(label)\n",
    "\n",
    "\n",
    "for y_pred, y_gold in zip([pred, adv_pred], [gold, gold]):\n",
    "    # for a pair\n",
    "    accuracy = np.sum(np.array(y_pred) == np.array(y_gold)) / len(y_gold)\n",
    "    print(\"ACCURACY:\", accuracy)\n",
    "    # f1 score\n",
    "    for mode in ['macro']:\n",
    "        f1 = f1_score(y_gold, y_pred, average=mode)\n",
    "        print(f\"F1: {f1}\")\n",
    "    print('-------------------------\\n')\n",
    "\n",
    "    # confusion matrix\n",
    "    print(metrics.confusion_matrix(y_gold, y_pred), '\\n')\n",
    "# print(\"**********************\",len(pre))\n",
    "\n",
    "print(f\"adv check: {adv_check}, adv success: {adv_success}\")\n",
    "##\n",
    "print(f\"adv success rate: {(adv_success / adv_check) * 100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "103a2f26-382b-421f-9f18-fbce2def4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #0.50 perturbations\n",
    "\n",
    "# adv_check = 0; adv_success = 0\n",
    "\n",
    "# pred = []; adv_pred = []; gold = []; cnt = 0\n",
    "# for row in tqdm(rows, total=len(rows)):\n",
    "#     cnt = cnt+1\n",
    "\n",
    "#     predicted = model_module.run(row['text']) \n",
    "#     label = row['label']\n",
    "#     # print(predicted)\n",
    "    \n",
    "#     if predicted == label:\n",
    "#         adv_check += 1\n",
    "#         # rerun with adv claim\n",
    "#         # print(adv_rows[str(row['id'])]['adv_text'])\n",
    "#         adv_predicted = model_module.run(adv_rows[str(row['id'])]['adv_text_50'])\n",
    "#         print(\"adv_predicted\", adv_predicted, predicted)\n",
    "#         if adv_predicted != predicted:\n",
    "#             # on success\n",
    "#             adv_success += 1\n",
    "#     else:\n",
    "#         adv_predicted = predicted\n",
    "    \n",
    "\n",
    "#     pred.append(predicted); adv_pred.append(adv_predicted); gold.append(label)\n",
    "\n",
    "\n",
    "# for y_pred, y_gold in zip([pred, adv_pred], [gold, gold]):\n",
    "#     # for a pair\n",
    "#     accuracy = np.sum(np.array(y_pred) == np.array(y_gold)) / len(y_gold)\n",
    "#     print(\"ACCURACY:\", accuracy)\n",
    "#     # f1 score\n",
    "#     for mode in ['macro']:\n",
    "#         f1 = f1_score(y_gold, y_pred, average=mode)\n",
    "#         print(f\"F1: {f1}\")\n",
    "#     print('-------------------------\\n')\n",
    "\n",
    "#     # confusion matrix\n",
    "#     print(metrics.confusion_matrix(y_gold, y_pred), '\\n')\n",
    "# # print(\"**********************\",len(pre))\n",
    "\n",
    "# print(f\"adv check: {adv_check}, adv success: {adv_success}\")\n",
    "# ##\n",
    "# print(f\"adv success rate: {(adv_success / adv_check) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8a685-4ce1-430c-8b68-f8d3c219eece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (robust)",
   "language": "python",
   "name": "robust"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
