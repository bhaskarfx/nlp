{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c65dc24-47dd-4288-8c42-3512a3a78d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "import itertools\n",
    "import random\n",
    "from typing import List\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch,csv\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798fc690-7bdf-4669-a0d7-bfee4fcf083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select device GPU, CPU or any other\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e2dfc9-56d4-40cb-9fb5-2e7685acf10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     1266\n",
       "posiitve     853\n",
       "negative     363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Statistics\n",
    "d=pd.read_csv(\"data/train.csv\")\n",
    "d[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2419ce3f-9a9a-4298-aef4-0e89d6c08b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     305\n",
       "posiitve    219\n",
       "negative     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Statistics\n",
    "d=pd.read_csv(\"data/dev.csv\")\n",
    "d[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72811ed8-6331-4fc4-a85f-14eccc40ff1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neutral     386\n",
       "posiitve    280\n",
       "negative    110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Statistics\n",
    "d=pd.read_csv(\"data/test.csv\")\n",
    "d[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b4b21f-1acd-48ad-a58b-77c17a5d649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv and return list of instances\n",
    "\n",
    "def read_data(path, to_dataset=True):\n",
    "    '''\n",
    "    read csv and return list of instances\n",
    "    '''\n",
    "    rows = []; label_dict = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "    \n",
    "    # read data\n",
    "    df=pd.read_csv(path)\n",
    "    for i in range(len(df)):\n",
    "        text = df['tweet'].loc[i]\n",
    "        \n",
    "        #remove extra space\n",
    "        wrds = text.split(\" \")\n",
    "        new_wrds = [wrd.strip() for wrd in wrds]\n",
    "        text = \" \".join(new_wrds)\n",
    "        \n",
    "        label = df['label'].loc[i]\n",
    "        if(label in [\"posiitve\"]):\n",
    "            label=\"positive\"\n",
    "            \n",
    "        label = label_dict[label]\n",
    "        \n",
    "        \n",
    "        rows.append({\n",
    "            'id': i,\n",
    "            'text': text,\n",
    "            'label': label,\n",
    "        })\n",
    "        \n",
    "  \n",
    "    if to_dataset:\n",
    "        # to object\n",
    "        rows = datasets.Dataset.from_list(rows)\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f2400-20a6-4406-b046-5c7756eef766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c39209-f9db-4d1d-b7fa-ec1970112f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    '''\n",
    "    calculate accuracy\n",
    "    '''\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26252e2e-cf3b-4b9e-b438-c020298cdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT:\n",
    "    '''\n",
    "    with tokenizer and auto model\n",
    "    '''\n",
    "    def __init__(self, MODEL, num_labels):\n",
    "        '''\n",
    "        basic\n",
    "        '''\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=num_labels)\n",
    "    \n",
    "    def tokenize(self, samples):\n",
    "        '''\n",
    "        run tokenization\n",
    "        '''\n",
    "        return self.tokenizer(samples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    def run(self, sample):\n",
    "        '''\n",
    "        run for a single instance\n",
    "        '''\n",
    "        encoded_input = self.tokenizer(sample, return_tensors='pt')\n",
    "        # print(\"encoded\")\n",
    "        output = self.model(**encoded_input)['logits'][0].detach().numpy()\n",
    "\n",
    "        return np.argmax(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdea01ca-19ed-420e-a9c3-8a0902d127ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/robust/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"FacebookAI/roberta-base\"\n",
    "\n",
    "# init model\n",
    "model_module = BERT(MODEL, num_labels=3)\n",
    "\n",
    "# read dataset\n",
    "train_dataset = read_data('data/train.csv')\n",
    "dev_dataset = read_data('data/dev.csv')\n",
    "\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        'train': train_dataset, \n",
    "        'dev': dev_dataset, \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a360d3d-c910-4533-a3ae-7d75b9926940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label'],\n",
       "        num_rows: 2482\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'text', 'label'],\n",
       "        num_rows: 621\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c75bc46d-3b24-4662-82ef-de5dce363f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75e4648ebac4427b92ef80576c0c04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2482 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcb2604e5654db8a3f5b04dcf2d092a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/621 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize dataset (multiple examples at same time)\n",
    "tok_dataset = dataset.map(model_module.tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf9c1fe-f4a0-43a1-b75c-f0c9b614ed45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2482\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 621\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "input_ids\n",
    "These are the numerical representations of tokens from the model’s vocabulary.\n",
    "Each token is mapped to a unique ID.\n",
    "[101] → [CLS] (Start of sentence)\n",
    "102 → [SEP] (End of sentence)\n",
    "\n",
    "attention_mask\n",
    "Specifies which tokens should be attended to and which should be ignored (useful for padding).\n",
    "1 means the token is real, 0 means it's padding.\n",
    "\n",
    "token_type_ids (Segment IDs)\n",
    "Helps differentiate between two sequences in a single input.\n",
    "'''\n",
    "tok_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59430957-946a-40a3-8ef2-da35485bfcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0mment scroll kar kar ke hairan hogaye hum\n",
      "['<s>', 'c', '0', 'm', 'ment', 'Ġscroll', 'Ġk', 'ar', 'Ġk', 'ar', 'Ġke', 'Ġhair', 'an', 'Ġhog', 'aye', 'Ġhum', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[0, 438, 288, 119, 1757, 25715, 449, 271, 449, 271, 7321, 2549, 260, 25663, 18328, 10080, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tok_dataset[\"train\"][1][\"text\"])\n",
    "print(model_module.tokenizer.convert_ids_to_tokens(tok_dataset[\"train\"][1][\"input_ids\"]))\n",
    "print(tok_dataset[\"train\"][1][\"input_ids\"])\n",
    "# print(tok_dataset[\"train\"][0][\"token_type_ids\"])\n",
    "print(tok_dataset[\"train\"][1][\"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c809ae13-e215-458b-b73b-2790978cfa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/robust/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "# training_args = TrainingArguments(output_dir=\"./logs\", num_train_epochs=1, learning_rate=3e-05, eval_strategy=\"epoch\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./logs_roberta\",           # Where model checkpoints/logs will be saved\n",
    "    num_train_epochs=3,            # Number of training epochs\n",
    "    learning_rate=3e-05,           # Learning rate (3e-5 = 0.00003)\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",    # Evaluate the model at the end of each epoch\n",
    "    per_device_train_batch_size=8,  # Training batch size\n",
    "    per_device_eval_batch_size=8, # Eval batch size\n",
    "    load_best_model_at_end=True, # Load best model when training ends\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3831147e-f92f-464c-9324-04b3b3745310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='933' max='933' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [933/933 27:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.878172</td>\n",
       "      <td>0.611916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.915400</td>\n",
       "      <td>0.773167</td>\n",
       "      <td>0.657005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.915400</td>\n",
       "      <td>0.793167</td>\n",
       "      <td>0.674718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=933, training_loss=0.8120814218142919, metrics={'train_runtime': 1638.0625, 'train_samples_per_second': 4.546, 'train_steps_per_second': 0.57, 'total_flos': 1959142508402688.0, 'train_loss': 0.8120814218142919, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_module.model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_dataset[\"train\"],\n",
    "    eval_dataset=tok_dataset[\"dev\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa72fdf3-c0a5-4eeb-b6e7-2c19914714f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/robust/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Inferencing\n",
    "\n",
    "# dataset\n",
    "rows = read_data(\"data/test.csv\", to_dataset=False)\n",
    "\n",
    "#Load model \n",
    "MODEL = \"logs_roberta/\"\n",
    "\n",
    "model_module = BERT(MODEL, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5213351-5d58-42e3-869a-e3c0d0ee7f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 776/776 [00:46<00:00, 16.68it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = []; gold = []\n",
    "for row in tqdm(rows, total=len(rows)):\n",
    "    pred.append(model_module.run(row['text'])); gold.append(row['label'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e06dcf9-c59e-41ee-a53d-949629ec2669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.6469072164948454\n",
      "MACRO F1: 0.6039455522617522\n",
      "-------------------------\n",
      "[[ 54  49   7]\n",
      " [ 31 300  55]\n",
      " [ 22 110 148]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(np.array(pred) == np.array(gold)) / len(gold)\n",
    "print(\"ACCURACY:\", accuracy)\n",
    "\n",
    "# f1 score\n",
    "for mode in ['macro']:\n",
    "    f1 = f1_score(gold, pred, average=mode)\n",
    "    print(f\"{mode.upper()} F1: {f1}\")\n",
    "print('-------------------------')\n",
    "\n",
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(gold, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524f372-5e4b-4bec-a9a0-32fad61e4287",
   "metadata": {},
   "source": [
    "Evaluating Robustness of Sentiment Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cec3450-0c76-4342-b64b-265a61348f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate phonetic perturbations\n",
    "class PhoneticPerturbations():\n",
    "    \n",
    "    def __init__(\n",
    "        self, seed: int = 0):\n",
    "        \n",
    "        self.seed=seed\n",
    "        \n",
    "    \n",
    "    def pho_50(self, sentence: str):\n",
    "        random.seed(self.seed)\n",
    "        sentence_list = sentence.split()\n",
    "        l=len(sentence_list)\n",
    "        k_fifty=int(l/2)\n",
    "       \n",
    "        \n",
    "        if(k_fifty==0):\n",
    "            k_fifty=1\n",
    "       \n",
    "        perturbed_texts = []\n",
    "        subwrd_dict={\"aa\": \"a\", \"i\": \"ee\", \"r\": \"ri\", \"o\": \"oo\", \"au\": \"ou\", \"ka\": \"k\", \"kha\": \"kh\", \"ga\": \"g\", \n",
    "\t\t\t\t\"gha\": \"gh\", \"ca\": \"c\",\"cha\": \"ch\", \"sa\":\"sh\", \"jha\": \"jh\", \"bha\":\"v\", \"ta\": \"t\", \"tha\": \"th\", \"da\": \"d\", \"dha\": \"dh\", \"na\":\"n\", \n",
    "\t\t\t\t\"pa\": \"p\", \"pha\":\"f\", \"ba\": \"b\", \"ma\": \"m\", \"ya\":\"y\", \"ra\": \"rh\", \"la\": \"l\", \"ja\": \"z\", \"ha\": \"h\"}\n",
    "        sub_keys=subwrd_dict.keys();sub_wrds=subwrd_dict.values()\n",
    "        all_roots=list(subwrd_dict.keys())\n",
    "               \n",
    "        # Perturb the input sentence \n",
    "        cnt=1\n",
    "        for idx, word in enumerate(sentence_list):\n",
    "            \n",
    "            if(cnt>k_fifty):\n",
    "                break\n",
    "               \n",
    "            else:\n",
    "                for j in range(len(all_roots)):\n",
    "                    # print(all_roots[j])\n",
    "                    if(all_roots[j] in word):\n",
    "                        word=word.replace(all_roots[j], subwrd_dict[all_roots[j]])\n",
    "                    \n",
    "                sentence_list[idx]=word\n",
    "                cnt=cnt+1\n",
    "                \n",
    "\n",
    "        perturbed_texts=\" \".join(sentence_list)\n",
    "\n",
    "        return perturbed_texts\n",
    "\n",
    "    def pho_25(self, sentence: str):\n",
    "        random.seed(self.seed)\n",
    "        sentence_list = sentence.split()\n",
    "        l=len(sentence_list)\n",
    "        k_twentyfive=int(l/4)\n",
    "       \n",
    "        \n",
    "        if(k_twentyfive==0):\n",
    "            k_twentyfive=1\n",
    "       \n",
    "        perturbed_texts = []\n",
    "        subwrd_dict={\"aa\": \"a\", \"i\": \"ee\", \"r\": \"ri\", \"o\": \"oo\", \"au\": \"ou\", \"ka\": \"k\", \"kha\": \"kh\", \"ga\": \"g\", \n",
    "\t\t\t\t\"gha\": \"gh\", \"ca\": \"c\",\"cha\": \"ch\", \"sa\":\"sh\", \"jha\": \"jh\", \"bha\":\"v\", \"ta\": \"t\", \"tha\": \"th\", \"da\": \"d\", \"dha\": \"dh\", \"na\":\"n\", \n",
    "\t\t\t\t\"pa\": \"p\", \"pha\":\"f\", \"ba\": \"b\", \"ma\": \"m\", \"ya\":\"y\", \"ra\": \"rh\", \"la\": \"l\", \"ja\": \"z\", \"ha\": \"h\"}\n",
    "        \n",
    "        sub_keys=subwrd_dict.keys();sub_wrds=subwrd_dict.values()\n",
    "        all_roots=list(subwrd_dict.keys())\n",
    "               \n",
    "        # Perturb the input sentence \n",
    "        cnt=1\n",
    "        for idx, word in enumerate(sentence_list):\n",
    "            \n",
    "            if(cnt>k_twentyfive):\n",
    "                break\n",
    "               \n",
    "            else:\n",
    "                for j in range(len(all_roots)):\n",
    "                    # print(all_roots[j])\n",
    "                    if(all_roots[j] in word):\n",
    "                        word=word.replace(all_roots[j], subwrd_dict[all_roots[j]])\n",
    "                    \n",
    "                sentence_list[idx]=word\n",
    "                cnt=cnt+1\n",
    "                \n",
    "\n",
    "        perturbed_texts=\" \".join(sentence_list)\n",
    "\n",
    "        return perturbed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d80c7033-05e1-4061-a3c6-6cfd095017d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=PhoneticPerturbations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f78f2073-f2c6-4d1a-ae6f-f9fbaf9aac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776 Index(['Unnamed: 0', 'tweet', 'label'], dtype='object')\n",
      "Index(['Unnamed: 0', 'tweet', 'label', 'adv_text_50', 'adv_text_25'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Read test file and apply perturbations\n",
    "\n",
    "df=pd.read_csv(\"data/test.csv\")\n",
    "print(len(df), df.columns)\n",
    "\n",
    "adv_text_50=[];adv_text_25=[]\n",
    "for i in range(len(df)):\n",
    "    t=pp.pho_50(df.tweet.loc[i])\n",
    "    t1=pp.pho_25(df.tweet.loc[i])\n",
    "    \n",
    "    adv_text_50.append(t)\n",
    "    adv_text_25.append(t1)\n",
    "    \n",
    "df[\"adv_text_50\"] = adv_text_50\n",
    "df[\"adv_text_25\"] = adv_text_25\n",
    "\n",
    "print(df.columns)\n",
    "df.to_csv(\"data/adv_test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe98cbba-fe31-46fb-80ad-4d2f9c23be05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kon kareaga rea terea sath bt tujhsea acha dog sea bt kr lu\n",
      "Koon krieag riea terea sath bt tujhsea acha dog sea bt kr lu\n",
      "Koon krieag riea teriea shth bt tujhsea acha dog sea bt kr lu\n"
     ]
    }
   ],
   "source": [
    "print(df[\"tweet\"][0])\n",
    "print(df[\"adv_text_25\"][0])\n",
    "print(df[\"adv_text_50\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c7b0365-f831-44d5-8f60-4752570a4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model on perturbed dataset#\n",
    "label_dict1 = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "def read_adv_data(path):\n",
    "    '''\n",
    "    read adv csv\n",
    "    '''\n",
    "    dataset = {}\n",
    "    cnt=0\n",
    "    with open(path, mode ='r') as f:\n",
    "        data_f = csv.reader(f)\n",
    "        # skip header\n",
    "        next(data_f)\n",
    "\n",
    "        for line in data_f:\n",
    "            cnt=cnt+1\n",
    "            # print(\"hiiiiiii\",cnt,line)\n",
    "            # label = label_dict1[line[-1]]\n",
    "            label = line[3]\n",
    "\n",
    "            dataset[str(line[0])] = {\n",
    "                'adv_text_25': line[4].strip(),\n",
    "                'adv_text_50': line[3].strip(),\n",
    "                'label': label\n",
    "            }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "801c102b-23ec-4559-af56-972839b5b11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 776 776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/robust/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "rows = read_data(\"data/test.csv\", to_dataset=False)\n",
    "\n",
    "# load adv dataset\n",
    "adv_rows = read_adv_data(\"data/adv_test_set.csv\")\n",
    "\n",
    "print(\"len\", len(rows), len(adv_rows))\n",
    "\n",
    "MODEL = \"./logs_roberta\"\n",
    "# init model\n",
    "model_module = BERT(MODEL, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30d84e9d-5e17-46a2-bd56-5108bb953b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 776/776 [00:44<00:00, 17.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.6469072164948454\n",
      "F1: 0.6039455522617522\n",
      "F1: 0.6417168056164244\n",
      "-------------------------\n",
      "\n",
      "[[ 54  49   7]\n",
      " [ 31 300  55]\n",
      " [ 22 110 148]] \n",
      "\n",
      "ACCURACY: 0.5476804123711341\n",
      "F1: 0.47202375336697133\n",
      "F1: 0.5315857891446596\n",
      "-------------------------\n",
      "\n",
      "[[ 31  69  10]\n",
      " [ 35 288  63]\n",
      " [ 25 149 106]] \n",
      "\n",
      "adv check: 502, adv success: 77\n",
      "adv success rate: 15.338645418326694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 0.25 perturbations\n",
    "\n",
    "adv_check = 0; adv_success = 0\n",
    "\n",
    "pred = []; adv_pred = []; gold = []; cnt = 0\n",
    "for row in tqdm(rows, total=len(rows)):\n",
    "    cnt = cnt+1\n",
    "\n",
    "    predicted = model_module.run(row['text']) \n",
    "    label = row['label']\n",
    "    # print(predicted,label)\n",
    "    \n",
    "    if predicted == label:\n",
    "        adv_check += 1\n",
    "        # rerun with adv claim\n",
    "        # print(adv_rows[str(row['id'])]['adv_text'])\n",
    "        adv_predicted = model_module.run(adv_rows[str(row['id'])]['adv_text_25'])\n",
    "        # print(\"adv_predicted\", adv_predicted, predicted)\n",
    "        if adv_predicted != predicted:\n",
    "            # on success\n",
    "            adv_success += 1\n",
    "    else:\n",
    "        adv_predicted = predicted\n",
    "    \n",
    "\n",
    "    pred.append(predicted); adv_pred.append(adv_predicted); gold.append(label)\n",
    "\n",
    "\n",
    "for y_pred, y_gold in zip([pred, adv_pred], [gold, gold]):\n",
    "    # for a pair\n",
    "    accuracy = np.sum(np.array(y_pred) == np.array(y_gold)) / len(y_gold)\n",
    "    print(\"ACCURACY:\", accuracy)\n",
    "    # f1 score\n",
    "    for mode in ['macro', 'weighted']:\n",
    "        f1 = f1_score(y_gold, y_pred, average=mode)\n",
    "        print(f\"F1: {f1}\")\n",
    "    print('-------------------------\\n')\n",
    "\n",
    "    # confusion matrix\n",
    "    print(metrics.confusion_matrix(y_gold, y_pred), '\\n')\n",
    "# print(\"**********************\",len(pre))\n",
    "\n",
    "print(f\"adv check: {adv_check}, adv success: {adv_success}\")\n",
    "##\n",
    "print(f\"adv success rate: {(adv_success / adv_check) * 100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a2f26-382b-421f-9f18-fbce2def4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.50 perturbations\n",
    "\n",
    "adv_check = 0; adv_success = 0\n",
    "\n",
    "pred = []; adv_pred = []; gold = []; cnt = 0\n",
    "for row in tqdm(rows, total=len(rows)):\n",
    "    cnt = cnt+1\n",
    "\n",
    "    predicted = model_module.run(row['text']) \n",
    "    label = row['label']\n",
    "    # print(predicted)\n",
    "    \n",
    "    if predicted == label:\n",
    "        adv_check += 1\n",
    "        # rerun with adv claim\n",
    "        # print(adv_rows[str(row['id'])]['adv_text'])\n",
    "        adv_predicted = model_module.run(adv_rows[str(row['id'])]['adv_text_50'])\n",
    "        # print(\"adv_predicted\", adv_predicted, predicted)\n",
    "        if adv_predicted != predicted:\n",
    "            # on success\n",
    "            adv_success += 1\n",
    "    else:\n",
    "        adv_predicted = predicted\n",
    "    \n",
    "\n",
    "    pred.append(predicted); adv_pred.append(adv_predicted); gold.append(label)\n",
    "\n",
    "\n",
    "for y_pred, y_gold in zip([pred, adv_pred], [gold, gold]):\n",
    "    # for a pair\n",
    "    accuracy = np.sum(np.array(y_pred) == np.array(y_gold)) / len(y_gold)\n",
    "    print(\"ACCURACY:\", accuracy)\n",
    "    # f1 score\n",
    "    for mode in ['macro', 'weighted']:\n",
    "        f1 = f1_score(y_gold, y_pred, average=mode)\n",
    "        print(f\"{mode.upper()} F1: {f1}\")\n",
    "    print('-------------------------\\n')\n",
    "\n",
    "    # confusion matrix\n",
    "    print(metrics.confusion_matrix(y_gold, y_pred), '\\n')\n",
    "# print(\"**********************\",len(pre))\n",
    "\n",
    "print(f\"adv check: {adv_check}, adv success: {adv_success}\")\n",
    "##\n",
    "print(f\"adv success rate: {(adv_success / adv_check) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8a685-4ce1-430c-8b68-f8d3c219eece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49f3aa-f19e-4bee-81ee-1da8da0bded3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (robust)",
   "language": "python",
   "name": "robust"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
